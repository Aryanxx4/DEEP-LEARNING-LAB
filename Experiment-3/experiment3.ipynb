{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91278e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Zip file is empty (0 bytes). Please download the dogs-vs-cats dataset.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "# Extract the dogs-vs-cats.zip file from the data folder\n",
    "zip_path = './data/dogs-vs-cats.zip'\n",
    "extract_path = './data/'\n",
    "\n",
    "if os.path.exists(zip_path):\n",
    "    try:\n",
    "        # Check if file is not empty\n",
    "        if os.path.getsize(zip_path) == 0:\n",
    "            print(f\"Error: Zip file is empty (0 bytes). Please download the dogs-vs-cats dataset.\")\n",
    "        else:\n",
    "            with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                zip_ref.extractall(extract_path)\n",
    "            print(f\"Successfully extracted {zip_path}\")\n",
    "            print(\"Contents:\", os.listdir(extract_path))\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Error: {zip_path} is corrupted or not a valid zip file. Please download it again.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "else:\n",
    "    print(f\"Zip file not found at {zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f571379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local environment - set data paths as needed\n"
     ]
    }
   ],
   "source": [
    "# For local environment: specify your data directory path\n",
    "# uploaded = './data/'  # or your desired data path\n",
    "print(\"Using local environment - set data paths as needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9c7e6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import copy\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "472b9a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [10:25<00:00, 273kB/s]  \n",
      "/Users/aryan/DEEP-LEARNING LAB/.venv/lib/python3.13/site-packages/torchvision/datasets/cifar.py:83: VisibleDeprecationWarning: dtype(): align should be passed as Python or NumPy boolean but got `align=0`. Did you mean to pass a tuple to create a subarray type? (Deprecated NumPy 2.4)\n",
      "  entry = pickle.load(f, encoding=\"latin1\")\n"
     ]
    }
   ],
   "source": [
    "transform_cifar = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "train_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "test_cifar  = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
    "\n",
    "train_loader_cifar = DataLoader(train_cifar, batch_size=64, shuffle=True)\n",
    "test_loader_cifar  = DataLoader(test_cifar, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de9a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted train.zip\n",
      "Extracted and renamed test1.zip to test\n",
      "Organized train data into cats and dogs folders\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in ./data/dogs-vs-cats/test.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 54\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Load datasets using ImageFolder\u001b[39;00m\n\u001b[32m     53\u001b[39m train_dogs = datasets.ImageFolder(train_path, transform=transform_dogs)\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m test_dogs  = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform_dogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m train_loader_dogs = DataLoader(train_dogs, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     57\u001b[39m test_loader_dogs  = DataLoader(test_dogs, batch_size=\u001b[32m32\u001b[39m, shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DEEP-LEARNING LAB/.venv/lib/python3.13/site-packages/torchvision/datasets/folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DEEP-LEARNING LAB/.venv/lib/python3.13/site-packages/torchvision/datasets/folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DEEP-LEARNING LAB/.venv/lib/python3.13/site-packages/torchvision/datasets/folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/DEEP-LEARNING LAB/.venv/lib/python3.13/site-packages/torchvision/datasets/folder.py:43\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     41\u001b[39m classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os.scandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m class_to_idx = {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Couldn't find any class folder in ./data/dogs-vs-cats/test."
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "transform_dogs = transforms.Compose([\n",
    "    transforms.Resize((128,128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Extract and organize dogs-vs-cats dataset\n",
    "zip_dir = './data/dogs-vs-cats'\n",
    "train_zip = os.path.join(zip_dir, 'train.zip')\n",
    "test_zip = os.path.join(zip_dir, 'test1.zip')\n",
    "train_path = os.path.join(zip_dir, 'train')\n",
    "test_path = os.path.join(zip_dir, 'test')\n",
    "\n",
    "# Extract train.zip if not already extracted\n",
    "if os.path.exists(train_zip) and not os.path.exists(os.path.join(zip_dir, 'train', 'cats')):\n",
    "    with zipfile.ZipFile(train_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(zip_dir)\n",
    "    print(\"Extracted train.zip\")\n",
    "\n",
    "# Extract test1.zip if not already extracted\n",
    "if os.path.exists(test_zip) and not os.path.exists(os.path.join(zip_dir, 'test_organized')):\n",
    "    with zipfile.ZipFile(test_zip, 'r') as zip_ref:\n",
    "        zip_ref.extractall(zip_dir)\n",
    "    os.rename(os.path.join(zip_dir, 'test1'), os.path.join(zip_dir, 'test_organized'))\n",
    "    print(\"Extracted and renamed test1.zip to test_organized\")\n",
    "\n",
    "# Organize train directory into class folders (cats/dogs) if needed\n",
    "train_cats_dir = os.path.join(train_path, 'cats')\n",
    "train_dogs_dir = os.path.join(train_path, 'dogs')\n",
    "\n",
    "if not os.path.exists(train_cats_dir):\n",
    "    os.makedirs(train_cats_dir, exist_ok=True)\n",
    "if not os.path.exists(train_dogs_dir):\n",
    "    os.makedirs(train_dogs_dir, exist_ok=True)\n",
    "    \n",
    "    # Move cat and dog images to respective folders\n",
    "    for file in os.listdir(train_path):\n",
    "        if file.startswith('cat.') and file.endswith('.jpg'):\n",
    "            shutil.move(os.path.join(train_path, file), os.path.join(train_cats_dir, file))\n",
    "        elif file.startswith('dog.') and file.endswith('.jpg'):\n",
    "            shutil.move(os.path.join(train_path, file), os.path.join(train_dogs_dir, file))\n",
    "    print(\"Organized train data into cats and dogs folders\")\n",
    "\n",
    "# Load training dataset using ImageFolder\n",
    "train_dogs = datasets.ImageFolder(train_path, transform=transform_dogs)\n",
    "\n",
    "# For test data (which has no labels), create dummy labels directory structure\n",
    "test_dummy_path = os.path.join(zip_dir, 'test_dummy')\n",
    "test_dummy_images = os.path.join(test_dummy_path, 'images')\n",
    "if not os.path.exists(test_dummy_images):\n",
    "    os.makedirs(test_dummy_images, exist_ok=True)\n",
    "    # Copy all test images to a single class directory\n",
    "    test_org_path = os.path.join(zip_dir, 'test_organized')\n",
    "    for file in os.listdir(test_org_path):\n",
    "        if file.endswith('.jpg'):\n",
    "            src = os.path.join(test_org_path, file)\n",
    "            dst = os.path.join(test_dummy_images, file)\n",
    "            if not os.path.exists(dst):\n",
    "                shutil.copy(src, dst)\n",
    "    print(\"Organized test data\")\n",
    "\n",
    "test_dogs = datasets.ImageFolder(test_dummy_path, transform=transform_dogs)\n",
    "\n",
    "train_loader_dogs = DataLoader(train_dogs, batch_size=32, shuffle=True)\n",
    "test_loader_dogs  = DataLoader(test_dogs, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Classes:\", train_dogs.classes)\n",
    "print(f\"Training samples: {len(train_dogs)}, Test samples: {len(test_dogs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661ac425",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self, num_classes, activation):\n",
    "        super(CustomCNN, self).__init__()\n",
    "\n",
    "        if activation == \"relu\":\n",
    "            act = nn.ReLU()\n",
    "        elif activation == \"tanh\":\n",
    "            act = nn.Tanh()\n",
    "        else:\n",
    "            act = nn.LeakyReLU()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            act,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            act,\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            act,\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128*8*8, 256),\n",
    "            act,\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac00763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(model, init_type):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "            if init_type == \"xavier\":\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif init_type == \"kaiming\":\n",
    "                nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "            else:\n",
    "                nn.init.normal_(m.weight, mean=0.0, std=0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db1ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "    return running_loss/len(loader), correct/len(loader.dataset)\n",
    "\n",
    "\n",
    "def eval_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "\n",
    "    return running_loss/len(loader), correct/len(loader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037a271",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [\"relu\", \"tanh\", \"leaky\"]\n",
    "inits = [\"xavier\", \"kaiming\", \"random\"]\n",
    "optimizers_list = [\"sgd\", \"adam\", \"rmsprop\"]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_models = {}\n",
    "\n",
    "for act, init, opt in itertools.product(activations, inits, optimizers_list):\n",
    "    print(f\"\\nConfig: {act} | {init} | {opt}\")\n",
    "\n",
    "    model = CustomCNN(num_classes=10, activation=act).to(device)\n",
    "    init_weights(model, init)\n",
    "\n",
    "    if opt == \"sgd\":\n",
    "        optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    elif opt == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    else:\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        train_loss, train_acc = train_model(model, train_loader_cifar, criterion, optimizer)\n",
    "        val_loss, val_acc = eval_model(model, test_loader_cifar, criterion)\n",
    "        print(f\"Epoch {epoch+1}: Val Acc={val_acc:.4f}\")\n",
    "\n",
    "    best_models[f\"{act}_{init}_{opt}\"] = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "  resnet = models.resnet18(pretrained=True)\n",
    "\n",
    "  for param in resnet.parameters():\n",
    "      param.requires_grad = False\n",
    "\n",
    "  resnet.fc = nn.Linear(resnet.fc.in_features, 10)\n",
    "  resnet = resnet.to(device)\n",
    "\n",
    "  optimizer = optim.Adam(resnet.fc.parameters(), lr=0.001)\n",
    "\n",
    "  for epoch in range(5):\n",
    "      train_loss, train_acc = train_model(resnet, train_loader_cifar, criterion, optimizer)\n",
    "      val_loss, val_acc = eval_model(resnet, test_loader_cifar, criterion)\n",
    "      print(f\"ResNet Epoch {epoch+1} Acc={val_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
